<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rishab K Pattnaik | Portfolio</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <link rel="stylesheet" href="static/css/main.css">
    <link rel="stylesheet" href="static/css/animations.css">
    <script>
        // Apply theme immediately to prevent flash of wrong theme
        const savedTheme = localStorage.getItem('theme');
        if (savedTheme === 'light') {
            // Wait for body to be available
            document.addEventListener('DOMContentLoaded', () => {
                document.body.classList.add('light-theme');
                const icon = document.querySelector('#themeToggle i');
                if (icon) {
                    icon.classList.remove('fa-sun');
                    icon.classList.add('fa-moon');
                }
            });
        }
    </script>
</head>
<body>
    <button class="theme-toggle" id="themeToggle">
        <i class="fas fa-sun"></i>
        <span>Toggle Theme</span>
    </button>

    <!--------------------------------------Navigation Section-------------------------------------------->
<nav class="nav-container">
    <div class="nav-links">
        <a href="#home">Home</a>
        <a href="#about">About Me</a>
        <a href="#experience">Experience</a>
        <a href="#research">Research & Publications</a>
        <a href="#project">Projects</a>
        <a href="#skills">Skills</a>
        <a href="#education">Education</a>
    </div>
</nav>

    <!------------------------------------------Home Section-------------------------------->
    <section id="home" class="header-section scroll-animation">
        <figure class="profile-photo">
            <img src="https://storage.googleapis.com/kaggle-avatars/images/21226742-kg.jpg" 
                 alt="Rishab K Pattnaik"
                 width="300" 
                 height="300">
        </figure>
        <h1 class="main-heading neon-reveal">Hi, Myself Rishab K Pattnaik</h1>
        <p class="sub-heading scroll-animation typing-animation">
          <span class="typing"></span>
        </p>

        <div class="button-container scroll-animation">
            <a href="https://drive.google.com/file/d/1Q7qsYgSI8bqhotXvoVuckmsygpDKQo1S/view?usp=sharing" target="_blank" class="social-btn">
                <i class="fas fa-file-alt"></i>
                <span>Resume</span>
            </a>
            <a href="https://github.com/Riiishaab" target="_blank" class="social-btn">
                <i class="fab fa-github"></i>
                <span>GitHub</span>
            </a>
            <a href="https://www.linkedin.com/in/rishab-kumar-pattnaik-6a9939249/" target="_blank" class="social-btn">
                <i class="fab fa-linkedin"></i>
                <span>LinkedIn</span>
            </a>
            <a href="mailto:f20220491@hyderabad.bits-pilani.ac.in" class="social-btn">
                <i class="fas fa-envelope"></i>
                <span>Email</span>
            </a>
        </div>
    </section>
  
  <!----------------------------------------------About Section------------------------------------------->
<section id="about" class="section about-section scroll-animation">
    <h2 class="section-title">Who I Am</h2>
    
    <p class="about-description">
        <span class="hover-blue">Driven</span> <span class="hover-blue">BE</span> <span class="hover-blue">Electronics</span> <span class="hover-blue">and</span> <span class="hover-blue">Communication</span> <span class="hover-blue">Engineer</span> <span class="hover-blue">with</span> <span class="hover-blue">a</span> <span class="hover-blue">passion</span> <span class="hover-blue">for</span> <span class="hover-blue">Machine</span> <span class="hover-blue">Learning</span> <span class="hover-blue">and</span> <span class="hover-blue">Artificial</span> <span class="hover-blue">Intelligence,</span> <span class="hover-blue">specializing</span> <span class="hover-blue">in</span> <span class="hover-blue">developing</span> <span class="hover-blue">innovative</span> <span class="hover-blue">AI</span> <span class="hover-blue">solutions</span> <span class="hover-blue">for</span> <span class="hover-blue">real-world</span> <span class="hover-blue">challenges.</span> <span class="hover-blue">I</span> <span class="hover-blue">bridge</span> <span class="hover-blue">the</span> <span class="hover-blue">gap</span> <span class="hover-blue">between</span> <span class="hover-blue">cutting-edge</span> <span class="hover-blue">research</span> <span class="hover-blue">and</span> <span class="hover-blue">practical</span> <span class="hover-blue">applications</span> <span class="hover-blue">with</span> <span class="hover-blue">a</span> <span class="hover-blue">robust</span> <span class="hover-blue">foundation</span> <span class="hover-blue">in</span> <span class="hover-blue">both</span> <span class="hover-blue">theory</span> <span class="hover-blue">and</span> <span class="hover-blue">implementation.</span> <span class="hover-blue">My</span> <span class="hover-blue">expertise</span> <span class="hover-blue">spans</span> <span class="hover-blue">computer</span> <span class="hover-blue">vision,</span> <span class="hover-blue">natural</span> <span class="hover-blue">language</span> <span class="hover-blue">processing,</span> <span class="hover-blue">and</span> <span class="hover-blue">generative</span> <span class="hover-blue">AI</span> <span class="hover-blue">technologies.</span> <span class="hover-blue">In</span> <span class="hover-blue">the</span> <span class="hover-blue">medical</span> <span class="hover-blue">domain,</span> <span class="hover-blue">I've</span> <span class="hover-blue">contributed</span> <span class="hover-blue">to</span> <span class="hover-blue">detection</span> <span class="hover-blue">and</span> <span class="hover-blue">classification</span> <span class="hover-blue">tasks,</span> <span class="hover-blue">implementing</span> <span class="hover-blue">various</span> <span class="hover-blue">deep</span> <span class="hover-blue">learning</span> <span class="hover-blue">architectures.</span> <span class="hover-blue">I</span> <span class="hover-blue">excel</span> <span class="hover-blue">in</span> <span class="hover-blue">experimenting</span> <span class="hover-blue">with</span> <span class="hover-blue">CNNs</span> <span class="hover-blue">and</span> <span class="hover-blue">Transformer</span> <span class="hover-blue">models,</span> <span class="hover-blue">incorporating</span> <span class="hover-blue">advanced</span> <span class="hover-blue">signal</span> <span class="hover-blue">processing</span> <span class="hover-blue">techniques</span> <span class="hover-blue">to</span> <span class="hover-blue">enhance</span> <span class="hover-blue">classification</span> <span class="hover-blue">accuracy.</span> <span class="hover-blue">This</span> <span class="hover-blue">approach</span> <span class="hover-blue">has</span> <span class="hover-blue">enabled</span> <span class="hover-blue">me</span> <span class="hover-blue">to</span> <span class="hover-blue">design</span> <span class="hover-blue">custom</span> <span class="hover-blue">neural</span> <span class="hover-blue">network</span> <span class="hover-blue">architectures</span> <span class="hover-blue">for</span> <span class="hover-blue">specific</span> <span class="hover-blue">challenges.</span> <span class="hover-blue">Committed</span> <span class="hover-blue">to</span> <span class="hover-blue">advancing</span> <span class="hover-blue">AI</span> <span class="hover-blue">applications</span> <span class="hover-blue">that</span> <span class="hover-blue">deliver</span> <span class="hover-blue">tangible</span> <span class="hover-blue">value,</span> <span class="hover-blue">I</span> <span class="hover-blue">combine</span> <span class="hover-blue">technical</span> <span class="hover-blue">excellence</span> <span class="hover-blue">with</span> <span class="hover-blue">practical</span> <span class="hover-blue">problem-solving</span> <span class="hover-blue">to</span> <span class="hover-blue">create</span> <span class="hover-blue">impactful</span> <span class="hover-blue">solutions</span>
    </p>
</section>


    <!-----------------------------------Experience Section---------------------------------------------->
    <section id="experience" class="section experience-section scroll-animation">
        <h2 class="section-title">Experience</h2>
        <div class="experience-container">
            <!-- Research Assistant -->
            <div class="experience-box scroll-animation">
               <h3><i class="fa fa-graduation-cap" style="margin-right: 10px;"></i>Research Assistant</h3>
                <p>As a Research Assistant in ECE at BITS Pilani Hyderabad under Dr. Rajesh Kumar Tripathy, I specialize in medical imaging using deep learning (CNNs, transformers) and wavelet-DNN integration.</p>
                <button class="show-details-btn" 
                        data-popup-trigger="experience-popup-1"
                        data-heading="Research Assistantship in Advanced Medical Imaging 🩺"
                        data-subheading="🤖 Deep Learning & Wavelet Integration 📡"
                        data-body="Advanced medical imaging through deep learning architectures and wavelet-DNN integration techniques. Achieved 5-15% accuracy improvements in abnormality detection across a diverse dataset exceeding 10,000 medical scans.

<h4>Technical Contributions</h4>

<h5>Transfer Learning Implementation</h5>
• Leveraged state-of-the-art architectures including EfficientNetV2B2 and ResNet50 as foundation models
• Adapted them specifically for medical imaging challenges through targeted fine-tuning protocols
• Enabled rapid knowledge transfer from general image recognition to specialized medical applications

<h5>Custom Architecture Development</h5>
• Designed bespoke CNN architectures with strategically configured multi-layer networks
• Addressed the unique characteristics of medical imaging data through specialized frameworks
• Provided valuable insights into optimal network design for specific diagnostic tasks

<h5>Deep Representation Learning</h5>
• Enhanced diagnostic accuracy by implementing deep representation learning techniques
• Augmented pre-trained models with custom classification layers
• Created robust feature representations particularly suited for complex medical abnormality detection

<h5>Wavelet Transform Integration</h5>
• Incorporated various wavelet transform methodologies into neural network frameworks
• Effectively captured multi-resolution features critical for medical image analysis
• Enhanced model sensitivity to subtle pathological indicators

<h5>Transformer Architecture Application</h5>
• Applied transformer-based architectures to medical imaging
• Harnessed attention mechanisms to focus on diagnostically relevant regions
• Maintained contextual awareness across the entire image

<h5>Current Research Focus</h5>
• Exploring diffusion models for generating synthetic medical imaging data
• Addressing dataset limitations in rare conditions
• Investigating advanced deep representation learning techniques
• Improving cross-modal generalizability across varying imaging modalities
• Enabling models to maintain performance across different acquisition parameters"
                        data-github="https://github.com/Riiishaab/OS-Detection-">
                    <span class="btn-text">Learn More</span>
                    <svg class="rocket-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                        <path d="M8 8c.828 0 1.5-.895 1.5-2S8.828 4 8 4s-1.5.895-1.5 2S7.172 8 8 8"/>
                        <path d="M11.953 8.81c-.195-3.388-.968-5.507-1.777-6.819C9.707 1.233 9.23.751 8.857.454a3.5 3.5 0 0 0-.463-.315A2 2 0 0 0 8.25.064.55.55 0 0 0 8 0a.55.55 0 0 0-.266.073 2 2 0 0 0-.142.08 4 4 0 0 0-.459.33c-.37.308-.844.803-1.31 1.57-.805 1.322-1.577 3.433-1.774 6.756l-1.497 1.826-.004.005A2.5 2.5 0 0 0 2 12.202V15.5a.5.5 0 0 0 .9.3l1.125-1.5c.166-.222.42-.4.752-.57.214-.108.414-.192.625-.281l.198-.084c.7.428 1.55.635 2.4.635s1.7-.207 2.4-.635q.1.044.196.083c.213.09.413.174.627.282.332.17.586.348.752.57l1.125 1.5a.5.5 0 0 0 .9-.3v-3.298a2.5 2.5 0 0 0-.548-1.562zM12 10.445v.055c0 .866-.284 1.585-.75 2.14.146.064.292.13.425.199.39.197.8.46 1.1.86L13 14v-1.798a1.5 1.5 0 0 0-.327-.935zM4.75 12.64C4.284 12.085 4 11.366 4 10.5v-.054l-.673.82a1.5 1.5 0 0 0-.327.936V14l.225-.3c.3-.4.71-.664 1.1-.861.133-.068.279-.135.425-.199M8.009 1.073q.096.06.226.163c.284.226.683.621 1.09 1.28C10.137 3.836 11 6.237 11 10.5c0 .858-.374 1.48-.943 1.893C9.517 12.786 8.781 13 8 13s-1.517-.214-2.057-.607C5.373 11.979 5 11.358 5 10.5c0-4.182.86-6.586 1.677-7.928.409-.67.81-1.082 1.096-1.32q.136-.113.236-.18Z"/>
                        <path d="M9.479 14.361c-.48.093-.98.139-1.479.139s-.999-.046-1.479-.139L7.6 15.8a.5.5 0 0 0 .8 0z"/>
                    </svg>
                    <div class="rocket-exhaust">
                        <div class="exhaust-flame"></div>
                    </div>
                </button>

            </div>

            <!-- Research Intern -->
            <div class="experience-box scroll-animation">
               <h3><i class="fa fa-laptop" style="margin-right: 10px;"></i>Research Intern</h3>
                <p>As a Research Intern at IGCAR Kalpakkam under Raja Sekhar M (SO/E), I experimented camouflaged object detection (COD), fine-tuning Meta's (Segment Anything Model) SAM.</p>
                <button class="show-details-btn" 
                        data-popup-trigger="experience-popup-2"
                        data-heading="Research Internship at IGCAR 🔬"
                        data-subheading="🦎 Camouflaged Object Detection 🕵️‍♂️"
                        data-body="During this internship, I specialized in addressing the challenging problem of camouflaged object detection (COD) by leveraging and fine-tuning Meta AI's Segment Anything Model (SAM). The project focused on developing robust methods to detect objects that blend seamlessly with their surroundings - a task where traditional computer vision approaches often fail. <h4>Project Implementation</h4> <h5>Dataset and Environment Setup</h5> - Utilized the COD10K dataset from Kaggle, which contains diverse images of camouflaged objects in natural settings - Implemented a custom dataset class and dataloader specifically designed for integration with SAM - Created a comprehensive data pipeline for preprocessing, including normalization and consistent resizing across the dataset <h5>Baseline Evaluation</h5> - Established performance benchmarks using the pre-trained SAM model without modifications - Employed SAM's Predictor and Automatic Mask Generator components to evaluate zero-shot performance - Identified specific limitations of SAM in the camouflaged object domain, confirming findings from recent research that SAM's performance on COD tasks is limited compared to its general segmentation capabilities <h5>Fine-Tuning Methodology</h5> - Developed a bounding box prompt-based approach to guide SAM's attention to regions containing camouflaged objects - Implemented a training engine to manage the fine-tuning process across multiple epochs - Optimized hyperparameters and loss functions specifically for the camouflaged object detection task - Monitored performance metrics throughout the training process to ensure continuous improvement <h5>Technical Innovations</h5> - Adapted SAM's promptable segmentation capabilities to the specific challenges of camouflaged objects - Implemented a box-prompt guided fine-tuning strategy that significantly improved detection accuracy - Designed a specialized training configuration that preserved SAM's general segmentation capabilities while enhancing its performance on camouflaged objects <h5>Quantified Results</h5> - Achieved a 14% improvement in mean Intersection over Union (mIoU) scores compared to the baseline pre-trained SAM model - Reduced false negative rates by approximately 22%, significantly improving the detection of highly camouflaged objects - Enhanced edge precision by 18%, allowing for more accurate delineation of camouflaged object boundaries - Maintained inference speed within 1.2x of the original model despite the additional fine-tuning - Demonstrated consistent performance improvements across various camouflage types (disruptive, coincident, and mimetic) in the COD10K dataset
This work contributes to the growing field of adapting foundation models like SAM to specialized domains, demonstrating that with appropriate fine-tuning strategies, these models can overcome their initial limitations in challenging visual tasks like camouflaged object detection."
                        data-github="https://github.com/Riiishaab/Camouflaged_Object_Detection/tree/main">
                    <span class="btn-text">Learn More</span>
                    <svg class="rocket-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                        <path d="M8 8c.828 0 1.5-.895 1.5-2S8.828 4 8 4s-1.5.895-1.5 2S7.172 8 8 8"/>
                        <path d="M11.953 8.81c-.195-3.388-.968-5.507-1.777-6.819C9.707 1.233 9.23.751 8.857.454a3.5 3.5 0 0 0-.463-.315A2 2 0 0 0 8.25.064.55.55 0 0 0 8 0a.55.55 0 0 0-.266.073 2 2 0 0 0-.142.08 4 4 0 0 0-.459.33c-.37.308-.844.803-1.31 1.57-.805 1.322-1.577 3.433-1.774 6.756l-1.497 1.826-.004.005A2.5 2.5 0 0 0 2 12.202V15.5a.5.5 0 0 0 .9.3l1.125-1.5c.166-.222.42-.4.752-.57.214-.108.414-.192.625-.281l.198-.084c.7.428 1.55.635 2.4.635s1.7-.207 2.4-.635q.1.044.196.083c.213.09.413.174.627.282.332.17.586.348.752.57l1.125 1.5a.5.5 0 0 0 .9-.3v-3.298a2.5 2.5 0 0 0-.548-1.562zM12 10.445v.055c0 .866-.284 1.585-.75 2.14.146.064.292.13.425.199.39.197.8.46 1.1.86L13 14v-1.798a1.5 1.5 0 0 0-.327-.935zM4.75 12.64C4.284 12.085 4 11.366 4 10.5v-.054l-.673.82a1.5 1.5 0 0 0-.327.936V14l.225-.3c.3-.4.71-.664 1.1-.861.133-.068.279-.135.425-.199M8.009 1.073q.096.06.226.163c.284.226.683.621 1.09 1.28C10.137 3.836 11 6.237 11 10.5c0 .858-.374 1.48-.943 1.893C9.517 12.786 8.781 13 8 13s-1.517-.214-2.057-.607C5.373 11.979 5 11.358 5 10.5c0-4.182.86-6.586 1.677-7.928.409-.67.81-1.082 1.096-1.32q.136-.113.236-.18Z"/>
                        <path d="M9.479 14.361c-.48.093-.98.139-1.479.139s-.999-.046-1.479-.139L7.6 15.8a.5.5 0 0 0 .8 0z"/>
                    </svg>
                    <div class="rocket-exhaust">
                        <div class="exhaust-flame"></div>
                    </div>
                </button>

            </div>

            <!-- eSports Coordinator -->
            <div class="experience-box scroll-animation">
                <h3><i class="fa fa-gamepad" style="margin-right: 10px;"></i>eSports Manager</h3
                <p>Led tournament organization and management at BITS Pilani Hyderabad, coordinating events with 100+ participants across 10 institutions. Created Python Program for fixture management dealing both even and odd participants.</p>
                <button class="show-details-btn" 
                        data-popup-trigger="experience-popup-3"
                        data-heading="Football Tournament Fixture Generator ⚽"
                        data-subheading=" 🏆 Streamlining Competition Management with Elegance and Precision 🥇"
                        data-body="<p>The Football Tournament Fixture Generator is a comprehensive tournament management system designed specifically for knockout-style football competitions. This Python-based application with a Tkinter interface offers tournament organizers a powerful yet intuitive solution for creating and managing competitive events.</p> <h4>Key Features</h4> <h5>Team Management</h5> - Easily register participating teams through a user-friendly interface with built-in validation to prevent duplicate entries - Support for various team sizes, with current implementation optimized for 5-7 teams - Comprehensive team data storage including team name, local town, and home stadium information <h5>Automated Fixture Generation</h5> - One-click random pairing of teams creates balanced tournament brackets - Implements Fisher-Yates shuffle algorithm to ensure fair and random match pairings - Handles special cases like derby matches between teams from the same town <h5>BYE Handling</h5> - Sophisticated handling of odd-numbered participant pools by automatically assigning 'BYE' slots - Ensures balanced competition regardless of participant numbers <h5>Round Progression</h5> - Seamless guidance through tournament stages from opening rounds to finals - Interactive interface for recording match results and advancing teams to subsequent rounds - Clear visualization of tournament progression using bracket-style layouts <h5>Schedule Management</h5> - Organizes matches into logical weekend groupings with only 4 teams playing per weekend - Ensures teams play home and away fixtures against each opponent - Prioritizes non-derby matches before scheduling teams from the same town <h5>Result Tracking</h5> - Interactive interface for recording match results and advancing teams - Options for both manual result entry and automated result generation for testing - Comprehensive tournament winner determination and display <h4>Technical Implementation</h4> <p>The application employs object-oriented design principles, separating tournament logic from the user interface. Core data structures include:</p>
Team struct: Stores team name, town, and stadium information

Match struct: Contains home and away teams, derby status, and leg information

Weekend Game struct: Organizes matches into weekend slots

<p>The system handles tournaments of various sizes through a modular architecture that ensures maintainability and extensibility. The fixture generation algorithm has O(n²) time complexity for match creation and employs sorting algorithms to ensure first legs are played before second legs.</p> <p>Output is available both through an interactive GUI and as CSV exports, making it easy to share and distribute fixture information to participants.</p> <p>This tool is particularly valuable for sports clubs, school competitions, or community events where organizing fair and transparent tournaments is essential. It simplifies the complex logistics of tournament management while providing a professional experience for both organizers and participants.</p>"
                        data-github="https://github.com/Riiishaab/Projects/blob/main/eSports_fixtures.py">
                    <span class="btn-text">Details</span>
                    <svg class="rocket-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                        <path d="M8 8c.828 0 1.5-.895 1.5-2S8.828 4 8 4s-1.5.895-1.5 2S7.172 8 8 8"/>
                        <path d="M11.953 8.81c-.195-3.388-.968-5.507-1.777-6.819C9.707 1.233 9.23.751 8.857.454a3.5 3.5 0 0 0-.463-.315A2 2 0 0 0 8.25.064.55.55 0 0 0 8 0a.55.55 0 0 0-.266.073 2 2 0 0 0-.142.08 4 4 0 0 0-.459.33c-.37.308-.844.803-1.31 1.57-.805 1.322-1.577 3.433-1.774 6.756l-1.497 1.826-.004.005A2.5 2.5 0 0 0 2 12.202V15.5a.5.5 0 0 0 .9.3l1.125-1.5c.166-.222.42-.4.752-.57.214-.108.414-.192.625-.281l.198-.084c.7.428 1.55.635 2.4.635s1.7-.207 2.4-.635q.1.044.196.083c.213.09.413.174.627.282.332.17.586.348.752.57l1.125 1.5a.5.5 0 0 0 .9-.3v-3.298a2.5 2.5 0 0 0-.548-1.562zM12 10.445v.055c0 .866-.284 1.585-.75 2.14.146.064.292.13.425.199.39.197.8.46 1.1.86L13 14v-1.798a1.5 1.5 0 0 0-.327-.935zM4.75 12.64C4.284 12.085 4 11.366 4 10.5v-.054l-.673.82a1.5 1.5 0 0 0-.327.936V14l.225-.3c.3-.4.71-.664 1.1-.861.133-.068.279-.135.425-.199M8.009 1.073q.096.06.226.163c.284.226.683.621 1.09 1.28C10.137 3.836 11 6.237 11 10.5c0 .858-.374 1.48-.943 1.893C9.517 12.786 8.781 13 8 13s-1.517-.214-2.057-.607C5.373 11.979 5 11.358 5 10.5c0-4.182.86-6.586 1.677-7.928.409-.67.81-1.082 1.096-1.32q.136-.113.236-.18Z"/>
                        <path d="M9.479 14.361c-.48.093-.98.139-1.479.139s-.999-.046-1.479-.139L7.6 15.8a.5.5 0 0 0 .8 0z"/>
                    </svg>
                    <div class="rocket-exhaust">
                        <div class="exhaust-flame"></div>
                    </div>
                </button>

            </div>
    </section>

    <!-- Research Section -->
    <section id="research" class="section research-section scroll-animation">
        <h2 class="section-title">Research & Publications</h2>
        <div class="research-container">
            <div class="research-box scroll-animation">
                <h3>Book Chapter on Deep Representation Learning</h3>
                <p>Published research in Elsevier's book on Signal Processing Driven Machine Learning Techniques for Cardiovascular Data Processing.</p>
                <button class="show-details-btn" 
                        data-popup-trigger="research-popup-1"
                        data-heading="Deep Learning for Medical Image Analysis"
                        data-subheading="Comparative Analysis of CNN and Vision Transformer Architectures"
                        data-body="Published research comparing CNN and Vision Transformer architectures in medical image classification. ViTs achieved 94.35% accuracy in osteoporosis detection and 96.57% accuracy in tuberculosis detection, demonstrating superior performance in handling complex medical imaging tasks."
                        data-github="https://github.com/Riiishaab/deep-representation-learning">
                    Show Details
                </button>
            </div>

            <div class="research-box scroll-animation">
                <h3>Ongoing Research</h3>
                <p>Currently working on advanced medical imaging applications using deep learning.</p>
                <button class="show-details-btn"
                        data-popup-trigger="research-popup-2"
                        data-heading="Upcoming Research"
                        data-subheading="Advanced Medical Imaging Applications"
                        data-body="Current research focuses on developing novel deep learning architectures for medical image analysis, with emphasis on improving diagnostic accuracy and computational efficiency."
                        data-github="         ">
                    Show Details
                </button>
            </div>
        </div>
    </section>

    <!-- Projects Section -->
    <section id="project" class="section project-section scroll-animation">
        <h2 class="section-title">Projects</h2>
        <div class="project-container">
          <div class="project-box scroll-animation">
                <h3><i class="fa fa-smile" style="margin-right: 10px;"></i>Expression.AI</h3>
                <p>Expression.AI is a real-time facial expression recognition Android app using TensorFlow Lite and OpenCV. It classifies emotions from camera or gallery images using a custom model trained on FER2013.</p>
                <button class="show-details-btn" 
                        data-popup-trigger="project-popup-4"
                        data-heading=" Expression.AI — Decode Emotions in Real-Time"
                        data-subheading="🎭  Feel the Mood. Frame by Frame. Powered by Deep Learning. 🎭 "
                        data-body="<p><strong>Expression.AI</strong> is a real-time facial expression recognition Android application that uses deep learning to detect and classify human emotions. Powered by a custom TensorFlow Lite model named <strong>ResInceptionCNN</strong>, the app is designed for fast, on-device inference and intuitive user experience. It combines the power of computer vision with emotion AI for mobile devices.</p> <p>App APK -> https://github.com/Riiishaab/Expression.AI/releases/download/v1.0/ExpressionAI.apk</p> <h3>Application Features</h3> <ul> <li>Real-time facial emotion detection using the device’s camera</li> <li>Supports classification from uploaded images via gallery</li> <li>Runs fully offline with no internet required for inference</li> <li>Emotion results displayed with matching emojis and labels</li> <li>Fast and efficient performance optimized for mobile usage</li> </ul> <h3>Model and Dataset</h3> <p>Expression.AI is built on a custom deep learning model trained for facial expression recognition:</p> <ul> <li><strong>Model Name</strong>: ResInceptionCNN — a hybrid architecture combining strengths of Residual and Inception networks</li> <li><strong>Dataset</strong>: Trained on the FER2013 dataset containing 48x48 grayscale facial images labeled with 7 emotion classes</li> <li><strong>Conversion</strong>: Exported to TensorFlow Lite format for mobile deployment</li> </ul> <h3>ResInceptionCNN Architecture</h3> <p>The core of the project is the ResInceptionCNN model:</p> <ul> <li><strong>Inception Blocks</strong>: Capture multi-scale spatial features for rich local and global context</li> <li><strong>Residual Connections</strong>: Enable deeper networks by addressing vanishing gradients and improving feature flow</li> <li><strong>Batch Normalization</strong>: Applied after each convolution to stabilize and speed up training</li> <li><strong>Dropout Layers</strong>: Reduce overfitting and improve generalization</li> <li><strong>Final Dense Layer</strong>: Outputs emotion class probabilities through a softmax activation</li> </ul> <h3>Technical Stack</h3> <ul> <li><strong>Android Studio</strong>: Used for developing the UI and app logic</li> <li><strong>TensorFlow Lite</strong>: Facilitates fast, on-device model inference</li> <li><strong>OpenCV</strong>: Handles face detection from camera and gallery inputs</li> <li><strong>CameraX</strong>: Provides real-time camera feed with face capture</li> </ul> <h3>Emotion Categories Detected</h3> <ul> <li>Angry 😠</li> <li>Disgust 😖</li> <li>Fear 😨</li> <li>Happy 😄</li> <li>Sad 😢</li> <li>Surprise 😲</li> <li>Neutral 😐</li> </ul> <h3>User Interface</h3> <ul> <li><strong>Live Camera View</strong>: Real-time emotion recognition with facial overlay</li> <li><strong>Image Upload</strong>: Choose from gallery for static image analysis</li> <li><strong>Emoji and Label Output</strong>: Emotion results shown with emojis and text</li> <li><strong>Minimal UI</strong>: Clean design with clear interaction flow and responsive layout</li> </ul> <p>This project demonstrates the potential of deep learning on edge devices, blending AI, mobile development, and human emotion understanding into a seamless Android experience.</p>"
                        data-github="https://github.com/Riiishaab/Expression.AI">
                    <span class="btn-text">Learn More</span>
                    <svg class="rocket-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                        <path d="M8 8c.828 0 1.5-.895 1.5-2S8.828 4 8 4s-1.5.895-1.5 2S7.172 8 8 8"/>
                        <path d="M11.953 8.81c-.195-3.388-.968-5.507-1.777-6.819C9.707 1.233 9.23.751 8.857.454a3.5 3.5 0 0 0-.463-.315A2 2 0 0 0 8.25.064.55.55 0 0 0 8 0a.55.55 0 0 0-.266.073 2 2 0 0 0-.142.08 4 4 0 0 0-.459.33c-.37.308-.844.803-1.31 1.57-.805 1.322-1.577 3.433-1.774 6.756l-1.497 1.826-.004.005A2.5 2.5 0 0 0 2 12.202V15.5a.5.5 0 0 0 .9.3l1.125-1.5c.166-.222.42-.4.752-.57.214-.108.414-.192.625-.281l.198-.084c.7.428 1.55.635 2.4.635s1.7-.207 2.4-.635q.1.044.196.083c.213.09.413.174.627.282.332.17.586.348.752.57l1.125 1.5a.5.5 0 0 0 .9-.3v-3.298a2.5 2.5 0 0 0-.548-1.562zM12 10.445v.055c0 .866-.284 1.585-.75 2.14.146.064.292.13.425.199.39.197.8.46 1.1.86L13 14v-1.798a1.5 1.5 0 0 0-.327-.935zM4.75 12.64C4.284 12.085 4 11.366 4 10.5v-.054l-.673.82a1.5 1.5 0 0 0-.327.936V14l.225-.3c.3-.4.71-.664 1.1-.861.133-.068.279-.135.425-.199M8.009 1.073q.096.06.226.163c.284.226.683.621 1.09 1.28C10.137 3.836 11 6.237 11 10.5c0 .858-.374 1.48-.943 1.893C9.517 12.786 8.781 13 8 13s-1.517-.214-2.057-.607C5.373 11.979 5 11.358 5 10.5c0-4.182.86-6.586 1.677-7.928.409-.67.81-1.082 1.096-1.32q.136-.113.236-.18Z"/>
                        <path d="M9.479 14.361c-.48.093-.98.139-1.479.139s-.999-.046-1.479-.139L7.6 15.8a.5.5 0 0 0 .8 0z"/>
                    </svg>
                    <div class="rocket-exhaust">
                        <div class="exhaust-flame"></div>
                    </div>
                </button>
            </div>

            <div class="project-box scroll-animation">
                <h3>Human Face Gender Detection</h3>
                <p>Deep learning-based gender detection system using CNN & InceptionV3.</p>
                <button class="show-details-btn"
                        data-popup-trigger="project-popup-2"
                        data-heading="GenderNet Vision"
                        data-subheading="Advanced Facial Analysis System"
                        data-body="Implemented a gender detection system using hybrid CNN-InceptionV3 architecture, achieving 94.35% accuracy on the CelebA dataset. Features include dynamic augmentation, adaptive learning rate scheduling, and quantized TensorFlow Lite deployment."
                        data-github="https://github.com/Riiishaab/Projects/blob/main/Face%20Gender%20Detection%20using%20CNNs.ipynb">
                    Show Details
                </button>
            </div>
            <div class="project-box scroll-animation">
               <h3><i class="fa fa-robot" style="margin-right: 10px;"></i>Smart AI Checkers Bot</h3>
                <p>A Checkers game featuring a Smart AI using Minimax with alpha-beta pruning against a Random AI, demonstrating strategic decision-making in game development with visual gameplay representation.</p>
                <button class="show-details-btn" 
                        data-popup-trigger="project-popup-3"
                        data-heading="THE ULTIMATE CHECKERS AI"
                        data-subheading="🎮Where Strategic Intelligence Conquers the Classic Game🎮"
                        data-body="This code implements a comprehensive Checkers (Draughts) game featuring two AI players with contrasting strategies: a sophisticated Smart AI using the Minimax algorithm with alpha-beta pruning and a baseline Random AI that makes random legal moves.</p> <h3>Game Structure</h3> <ul> <li>The game utilizes an 8×8 checkerboard grid with traditional alternating dark and light squares</li> <li>Two AI players compete: Red (Smart AI) and Blue (Random AI)</li> <li>Turn-based gameplay with visual representation of each move</li> <li>King promotion mechanics when pieces reach the opponent's back row</li> <li>Standard checkers rules including mandatory captures and multiple jumps</li> </ul> <h3>AI Implementation</h3> <p>The Minimax algorithm implementation represents the core intelligence of the Smart AI:</p> <ul> <li><strong>Depth-Limited Search</strong>: The Smart AI (Red player) looks ahead 3 moves using the Minimax algorithm</li> <li><strong>Alpha-Beta Pruning</strong>: Optimizes the search by eliminating branches that won't affect the final decision</li> <li><strong>Recursive Evaluation</strong>: Each potential move is evaluated by simulating future game states</li> <li><strong>Heuristic Evaluation</strong>: Board positions are scored based on piece count, king status, and positioning</li> <li><strong>Maximizing Strategy</strong>: The AI selects moves that maximize its advantage while assuming optimal opponent play</li> </ul> <p>The Random AI provides a contrasting approach:</p> <ul> <li>Identifies all pieces with legal moves</li> <li>Randomly selects one of these pieces</li> <li>Randomly selects one of the legal moves for that piece</li> <li>Executes without strategic planning</li> </ul> <h3>Game Mechanics</h3> <ul> <li><strong>Move Validation</strong>: Comprehensive checking of legal moves including diagonal movement and jumps</li> <li><strong>Capture Logic</strong>: Implementation of mandatory jump rules and multiple capture sequences</li> <li><strong>Visual Representation</strong>: Board state displayed using HTML/CSS with color-coded pieces</li> <li><strong>Game Termination</strong>: Ends after 100 moves or when a player has no remaining pieces/moves</li> <li><strong>Winner Determination</strong>: Based on remaining piece count or inability of opponent to move</li> </ul> <h3>User Interface</h3> <ul> <li><strong>Interactive Display</strong>: Color-coded pieces with clear visual distinction between regular pieces and kings</li> <li><strong>Move Animation</strong>: Step-by-step visualization with appropriate delays for user comprehension</li> <li><strong>Notifications</strong>: Popup alerts for game start, end, and important events</li> <li><strong>Status Updates</strong>: Ongoing information about game progress, turn count, and current player</li> <li><strong>Board Rendering</strong>: Clear representation of the current game state after each move</li> </ul> <p>This implementation demonstrates advanced concepts in game AI development.</p>"
                        data-github="https://github.com/Riiishaab/Projects/blob/main/my_smart_ai_checkers_bot.py">
                    <span class="btn-text">Learn More</span>
                    <svg class="rocket-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                        <path d="M8 8c.828 0 1.5-.895 1.5-2S8.828 4 8 4s-1.5.895-1.5 2S7.172 8 8 8"/>
                        <path d="M11.953 8.81c-.195-3.388-.968-5.507-1.777-6.819C9.707 1.233 9.23.751 8.857.454a3.5 3.5 0 0 0-.463-.315A2 2 0 0 0 8.25.064.55.55 0 0 0 8 0a.55.55 0 0 0-.266.073 2 2 0 0 0-.142.08 4 4 0 0 0-.459.33c-.37.308-.844.803-1.31 1.57-.805 1.322-1.577 3.433-1.774 6.756l-1.497 1.826-.004.005A2.5 2.5 0 0 0 2 12.202V15.5a.5.5 0 0 0 .9.3l1.125-1.5c.166-.222.42-.4.752-.57.214-.108.414-.192.625-.281l.198-.084c.7.428 1.55.635 2.4.635s1.7-.207 2.4-.635q.1.044.196.083c.213.09.413.174.627.282.332.17.586.348.752.57l1.125 1.5a.5.5 0 0 0 .9-.3v-3.298a2.5 2.5 0 0 0-.548-1.562zM12 10.445v.055c0 .866-.284 1.585-.75 2.14.146.064.292.13.425.199.39.197.8.46 1.1.86L13 14v-1.798a1.5 1.5 0 0 0-.327-.935zM4.75 12.64C4.284 12.085 4 11.366 4 10.5v-.054l-.673.82a1.5 1.5 0 0 0-.327.936V14l.225-.3c.3-.4.71-.664 1.1-.861.133-.068.279-.135.425-.199M8.009 1.073q.096.06.226.163c.284.226.683.621 1.09 1.28C10.137 3.836 11 6.237 11 10.5c0 .858-.374 1.48-.943 1.893C9.517 12.786 8.781 13 8 13s-1.517-.214-2.057-.607C5.373 11.979 5 11.358 5 10.5c0-4.182.86-6.586 1.677-7.928.409-.67.81-1.082 1.096-1.32q.136-.113.236-.18Z"/>
                        <path d="M9.479 14.361c-.48.093-.98.139-1.479.139s-.999-.046-1.479-.139L7.6 15.8a.5.5 0 0 0 .8 0z"/>
                    </svg>
                    <div class="rocket-exhaust">
                        <div class="exhaust-flame"></div>
                    </div>
                </button>

            </div>
          
            <div class="project-box scroll-animation">
                <h3>AI Document Assistant</h3>
                <p>Smart document processing system using DeepSeek and Llama models.</p>
                <button class="show-details-btn" 
                        data-popup-trigger="project-popup-1"
                        data-heading="AI Document Processing System 📄"
                        data-subheading="🚀 Intelligent Document Analysis and Summarization 🚀"
                        data-body="Developed an AI-driven document processing system combining DeepSeek R1-1.5B for structured data extraction and Llama-7B for summarization. Achieved 92% accuracy in entity extraction and 88% ROUGE-L summarization scores, enabling efficient processing of legal and technical documents."
                        data-github="https://github.com/Riiishaab/Projects/tree/main/AI%20Document%20Assistant">
                    Show Details
                </button>
            </div>

            <div class="project-box scroll-animation">
                <h3><i class="fa fa-hand-scissors" style="margin-right: 10px;"></i>Hand Gesture Identifier</h3>
                <p>Vision Foundation model using FastViT by Apple for Hand Gesture Recognition.</p>
                <button class="show-details-btn" 
                        data-popup-trigger="project-popup-5"
                        data-heading="AI Hand Gesture Recognition System 🖐️"
                        data-subheading="🤟🏼 Real-time gesture recognition through FastViT Model ✌️"
                        data-body="<p>This project implements real-time hand gesture recognition using Apple’s FastViT architecture, leveraging transfer learning on the HaGRID dataset to achieve 97.5% accuracy while maintaining efficiency for real-time applications.</p>

<h3>🔑 Key Features</h3>
<ul>
  <li><strong>Real-time gesture recognition</strong> through webcam integration</li>
  <li><strong>19 different hand gestures</strong> recognized with high accuracy</li>
  <li><strong>Efficient model architecture</strong> using FastViT for low-latency predictions</li>
  <li><strong>Simple deployment</strong> through Google Colab (no local setup required)</li>
</ul>

<h3>🧠 Model &amp; Architecture</h3>
<p>The core intelligence is provided by a hybrid vision transformer:</p>
<ul>
  <li><strong>Backbone</strong>: <code>fastvit_t8.apple_in1k</code> pretrained model</li>
  <li><strong>Training approach</strong>: Transfer learning with a frozen backbone</li>
  <li><strong>Input size</strong>: 256×256 px</li>
  <li><strong>Classes</strong>: 19 hand gestures</li>
</ul>
<p>FastViT was chosen for its efficiency advantages over ConvNeXT, offering high accuracy in resource-constrained environments.</p>

<h3>📊 Dataset</h3>
<p>Trained on the Hand Gesture Recognition Image Dataset (<strong>HaGRID</strong>) 150k subset:</p>
<ul>
  <li><strong>19 gesture classes</strong> including “thumbs up”, “peace sign”, and “stop”</li>
  <li>Used the manageable <strong>150k version</strong> for Colab training</li>
  <li>Properly split between <strong>training</strong> and <strong>validation</strong> sets</li>
</ul>

<h3>🚀 Usage</h3>
<p><strong>Option 1: Google Colab</strong></p>
<ul>
  <li>Open the training notebook</li>
  <li>Run all cells to train or load pretrained weights</li>
  <li>Follow webcam integration instructions</li>
</ul>
<p><strong>Option 2: Inference with Pretrained Model</strong></p>
<ul>
  <li>Open the inference notebook</li>
  <li>Upload the pretrained model file (<code>sign_lang_model.pkl</code>)</li>
  <li>Run the webcam inference cell</li>
</ul>

<h3>📈 Results</h3>
<ul>
  <li><strong>97.5% accuracy</strong> on the validation set</li>
  <li>Robust across different lighting conditions</li>
  <li><strong>Real-time inference</strong> (>30 FPS on modern hardware)</li>
</ul>

<h3>🔮 Future Work</h3>
<ul>
  <li><strong>Expanded gesture vocabulary</strong>: Full sign language alphabet and phrases</li>
  <li><strong>Standalone deployment</strong>: Integration with video conferencing</li>
  <li><strong>Sequence modeling</strong>: Temporal information for dynamic gestures</li>
  <li><strong>Model optimization</strong>: Quantization and pruning for edge devices</li>
</ul>"
                        data-github="https://github.com/Riiishaab/Sign_Language_Detector">
                    Show Details
                </button>
            </div>

        </div>
    </section>

    <!-- Skills Section -->
    <section id="skills" class="skills-section">
        <h2 class="section-title scroll-animation">Skills</h2>
        <div class="skills-container">
            <!-- Programming Category -->
            <div class="skill-category scroll-animation">
                <h3>Programming Languages</h3>
                <div class="skills-grid">
                    <div class="skill-box scroll-animation">
                        <i class="fab fa-python" style="color: #3776ab;"></i>
                        <span class="skill-name">Python</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <span style="color: #004482; font-weight: bold;">C</span>
                        <span class="skill-name">C Programming</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-database" style="color: #f29111;"></i>
                        <span class="skill-name">SQL</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fab fa-git-alt" style="color: #f34f29;"></i>
                        <span class="skill-name">Git</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-microchip" style="color: #1a237e;"></i>
                        <span class="skill-name">Verilog</span>
                    </div>
                </div>
            </div>

            <!-- Frameworks & Libraries Category -->
            <div class="skill-category scroll-animation">
                <h3>Frameworks & Libraries</h3>
                <div class="skills-grid">
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-fire" style="color: #EE4C2C;"></i>
                        <span class="skill-name">PyTorch</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-project-diagram" style="color: #FF6F00;"></i>
                        <span class="skill-name">TensorFlow</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-eye" style="color: #007BFF;"></i>
                        <span class="skill-name">Computer Vision</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-robot" style="color: #F7931E;"></i>
                        <span class="skill-name">Scikit-learn</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-feather" style="color: #D00000;"></i>
                        <span class="skill-name">Keras</span>
                    </div>
                </div>
            </div>

            <!-- Domain Skills Category -->
            <div class="skill-category scroll-animation">
                <h3>Domain Skills</h3>
                <div class="skills-grid">
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-brain" style="color: #FFD700;"></i>
                        <span class="skill-name">Machine Learning</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-network-wired" style="color: #00FF00;"></i>
                        <span class="skill-name">Deep Learning</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-magic" style="color: #FF4500;"></i>
                        <span class="skill-name">Generative AI</span>
                    </div>
                    <div class="skill-box scroll-animation">
                        <i class="fas fa-comments" style="color: #1E90FF;"></i>
                        <span class="skill-name">LLM</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Education Section -->
    <section id="education" class="education-section scroll-animation">
        <h2 class="section-title">Education</h2>
        <div class="education-box scroll-animation">
            <h2 class="education-heading">Birla Institute of Technology and Science, Pilani</h2>
            <h3 class="degree-subheading">Bachelor of Engineering in Electronics and Communication Engineering</h3>
            <p class="location-text">Hyderabad, India • Currently Studying</p>

            <h4 class="coursework-heading">Relevant Coursework</h4>
            <ul class="coursework-list">
                <li class="coursework-item scroll-animation">Machine Learning for Electronics Engineer</li>
                <li class="coursework-item scroll-animation">Neural Network and Fuzzy Logic</li>
                <li class="coursework-item scroll-animation">Deep Learning</li>
                <li class="coursework-item scroll-animation">Digital Signal Processing</li>
                <li class="coursework-item scroll-animation">Signals and Systems</li>
                <li class="coursework-item scroll-animation">Computer Architecture</li>
                <li class="coursework-item scroll-animation">Microprocessor and Interfacing</li>
                <li class="coursework-item scroll-animation">Digital Design</li>
            </ul>
        </div>
    </section>

    <!-- Popup Containers -->
    <div id="experience-popup-1" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> Code
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>

    <div id="experience-popup-2" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> Code
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>

    <div id="experience-popup-3" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> Code
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>

    <div id="research-popup-1" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> View on GitHub
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>

    <div id="research-popup-2" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> View on GitHub
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>

    <div id="project-popup-1" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> View on GitHub
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>

    <div id="project-popup-2" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> View on GitHub
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>
  
     <div id="project-popup-3" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> Code
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>
      
    <div id="project-popup-4" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> Code
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>

    <div id="project-popup-5" class="popup">
        <div class="popup-content">
            <h2 class="popup-heading"></h2>
            <h3 class="popup-subheading"></h3>
            <div class="popup-body"></div>
            <div class="popup-buttons">
                <a href="" class="popup-github" target="_blank">
                    <i class="fab fa-github"></i> Code
                </a>
                <button class="popup-close">Close</button>
            </div>
        </div>
    </div>

    <script src="static/js/main.js"></script>
      
    <footer class="site-footer">
    <p>© Made by Rishab⚡</p>
    </footer>
</body>
</html>
